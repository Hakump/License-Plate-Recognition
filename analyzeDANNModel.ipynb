{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa56db76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8446, 32, 16, 3)\n",
      "load data finished!\n"
     ]
    }
   ],
   "source": [
    "import  os, glob\n",
    "import  random, csv\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import adapt\n",
    "from adapt.feature_based import DANN\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape,Conv2D,MaxPool2D,Flatten,Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "# The path of the datasets, use dict format\n",
    "dataset_path = {\"base\": \"dataset/ccpd/splitted_plates_base\", \n",
    "                \"challenge\":\"dataset/ccpd/splitted_plates_challenge\",\n",
    "               \"db\":\"dataset/ccpd/splitted_plates_db\",\n",
    "               \"fn\":\"dataset/ccpd/splitted_plates_fn\",\n",
    "               \"weather\":\"dataset/ccpd/splitted_plates_weather\"}\n",
    "# The path of the saving model check points\n",
    "save_check_pt = './checkpoints_DANN'\n",
    "\n",
    "def load_csv(root, filename, name2label):\n",
    "    # From csv file return images dir,labels list\n",
    "    if not os.path.exists(os.path.join(root, filename)):\n",
    "        images = []\n",
    "        for name in name2label.keys(): \n",
    "            images += glob.glob(os.path.join(root, name, '*.png'))\n",
    "            images += glob.glob(os.path.join(root, name, '*.jpg'))\n",
    "            images += glob.glob(os.path.join(root, name, '*.jpeg'))\n",
    "        #print(len(images), images)\n",
    "        random.shuffle(images) # shuffle images\n",
    "        with open(os.path.join(root, filename), mode='w', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            for img in images:  \n",
    "                name = img.split(os.sep)[-2]\n",
    "                label = name2label[name]\n",
    "                writer.writerow([img, label])\n",
    "            print('written into csv file:', filename)\n",
    "    # read existed csv\n",
    "    images, labels = [], []\n",
    "    with open(os.path.join(root, filename)) as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            img, label = row\n",
    "            label = int(label)\n",
    "            images.append(img)\n",
    "            labels.append(label) \n",
    "    # return img dir and label\n",
    "    return images, labels\n",
    "\n",
    "def load_ccpd(root, mode='train'):\n",
    "    name2label = {}  # \"sq...\":0\n",
    "    # iterate sub dir, sort, while keep mapping\n",
    "    for name in sorted(os.listdir(os.path.join(root))):\n",
    "        # skip non file folder\n",
    "        if not os.path.isdir(os.path.join(root, name)):\n",
    "            continue\n",
    "        # give each category a number\n",
    "        name2label[name] = len(name2label.keys())\n",
    "    images, labels = load_csv(root, 'images.csv', name2label)\n",
    "    if mode == 'train':  # 20%\n",
    "        images = images[:int(0.2 * len(images))]\n",
    "        labels = labels[:int(0.2 * len(labels))]\n",
    "    elif mode == 'val':  # 20% = 60%->80%\n",
    "        images = images[int(0.6 * len(images)):int(0.8 * len(images))]\n",
    "        labels = labels[int(0.6 * len(labels)):int(0.8 * len(labels))]\n",
    "    else:  # all\n",
    "        images = images\n",
    "        labels = labels\n",
    "    return images, labels, name2label\n",
    "\n",
    "def readCcpdImg(images_dir):\n",
    "    X = []\n",
    "    for img_dir in images_dir:\n",
    "        img = cv2.imread(img_dir)\n",
    "        img = cv2.resize(img,(16,32))\n",
    "        X.append(img)\n",
    "    X = np.array(X)\n",
    "    return X\n",
    "\n",
    "# def readCcpdImg(images_dir):\n",
    "#     X = []\n",
    "#     for img_dir in images_dir:\n",
    "#         img = Image.open(img_dir)\n",
    "#         img = img.convert('L') # conver to grayscale images\n",
    "#         img = img.resize([16, 32])\n",
    "#         img_np = np.asarray(img)\n",
    "#         X.append(img_np.reshape([-1]))\n",
    "#     X = np.array(X)\n",
    "#     return X\n",
    "\n",
    "def get_img_label(path, mode,num_classes=35):\n",
    "    images_dir, labels, table = load_ccpd(dataset_path[path],mode=mode)\n",
    "    images = readCcpdImg(images_dir)\n",
    "    labels = np.array(labels)\n",
    "    labels = to_categorical(labels, num_classes=num_classes)\n",
    "    return images,labels\n",
    "\n",
    "def get_encoder(input_shape=(32,16,3)):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=[3, 3], padding=\"same\", activation='relu',input_shape=input_shape))\n",
    "    model.add(MaxPool2D(pool_size=[2, 2], strides=2, padding='same'))\n",
    "    model.add(Conv2D(48, kernel_size=[3, 3], padding=\"same\", activation='relu'))\n",
    "    model.add(MaxPool2D(pool_size=[2, 2], strides=2, padding='same'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Activation('sigmoid'))\n",
    "    return model\n",
    "\n",
    "def get_task(input_shape=(1536,)):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1024, activation='relu',input_shape=input_shape))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(34, activation=\"softmax\"))\n",
    "    return model\n",
    "\n",
    "def get_discriminator(input_shape=(1536,)):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1024, activation='relu',input_shape=input_shape))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "base_images,base_labels = get_img_label('base', 'all', num_classes=34)\n",
    "weather_images,weather_labels = get_img_label('weather', 'all', num_classes=34)\n",
    "weather_images_t,weather_labels_t = get_img_label('weather', 'train', num_classes=34)\n",
    "challenge_images,challenge_labels = get_img_label('challenge', 'all', num_classes=34)\n",
    "challenge_images_t,challenge_labels_t = get_img_label('challenge', 'train', num_classes=34)\n",
    "db_images,db_labels = get_img_label('db', 'all', num_classes=34)\n",
    "db_images_t,db_labels_t = get_img_label('db', 'train', num_classes=34)\n",
    "fn_images,fn_labels = get_img_label('fn', 'all', num_classes=34)\n",
    "fn_images_t,fn_labels_t = get_img_label('fn', 'train', num_classes=34)\n",
    "print(np.shape(base_images))\n",
    "#model = get_encoder()\n",
    "#model.build(input_shape=[None, 32, 16, 3])\n",
    "#model.summary()\n",
    "print(\"load data finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6335631b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 446ms/step - loss: 0.2166 - acc: 0.9625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96       248\n",
      "           1       0.90      0.96      0.93       137\n",
      "           2       0.99      0.97      0.98       231\n",
      "           3       0.97      0.99      0.98       172\n",
      "           4       0.80      1.00      0.89        78\n",
      "           5       0.98      0.98      0.98       233\n",
      "           6       0.99      0.97      0.98       236\n",
      "           7       0.97      0.94      0.96       213\n",
      "           8       0.97      0.99      0.98       257\n",
      "           9       0.98      0.99      0.98       224\n",
      "          10       1.00      0.97      0.98       748\n",
      "          11       0.85      0.90      0.87        50\n",
      "          12       1.00      0.96      0.98        49\n",
      "          13       0.98      0.90      0.93        48\n",
      "          14       0.77      0.96      0.86        28\n",
      "          15       0.90      0.95      0.93        40\n",
      "          16       0.95      0.88      0.91        41\n",
      "          17       1.00      0.95      0.97        57\n",
      "          18       0.98      1.00      0.99        45\n",
      "          19       0.98      0.98      0.98        53\n",
      "          20       0.95      0.98      0.96        41\n",
      "          21       0.98      1.00      0.99        49\n",
      "          22       1.00      0.96      0.98        54\n",
      "          23       0.94      1.00      0.97        31\n",
      "          24       0.91      0.83      0.87        36\n",
      "          25       0.98      0.95      0.97        44\n",
      "          26       0.98      0.98      0.98        58\n",
      "          27       0.93      0.80      0.86        35\n",
      "          28       0.92      0.88      0.90        26\n",
      "          29       1.00      0.90      0.95        42\n",
      "          30       0.92      0.97      0.94        59\n",
      "          31       0.76      1.00      0.86        56\n",
      "          32       0.89      0.97      0.93        40\n",
      "          33       0.92      0.92      0.92        53\n",
      "\n",
      "    accuracy                           0.96      3812\n",
      "   macro avg       0.94      0.95      0.94      3812\n",
      "weighted avg       0.97      0.96      0.96      3812\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "#Dummy inputs to load model\n",
    "xs=np.zeros((8446, 32, 16, 3))\n",
    "ys=np.zeros((8446, 34))\n",
    "xt=np.zeros((762, 32, 16, 3))\n",
    "yt=np.zeros((762, 34))\n",
    "weather_model = DANN(get_encoder(), get_task(), get_discriminator(),\n",
    "             lambda_=0.1, optimizer=Adam(0.0001),loss='CategoricalCrossentropy',metrics=[\"acc\"],random_state=0)\n",
    "weather_model.fit(xs, ys,xt,yt, epochs=0,verbose=1,batch_size = 32) # NO fit happen, just dummy step to load model\n",
    "weather_model.load_weights(save_check_pt+ '/weather')\n",
    "weather_model.score(weather_images, weather_labels)\n",
    "weather_hat = weather_model.predict(weather_images)\n",
    "weather_hat = np.argmax(weather_hat,axis=1)\n",
    "weather_labels = np.argmax(weather_labels,axis=1)\n",
    "print(classification_report(weather_labels, weather_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8bd28db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 172ms/step - loss: 0.8332 - acc: 0.8686\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91        39\n",
      "           1       0.69      0.63      0.66        38\n",
      "           2       0.94      0.97      0.95        30\n",
      "           3       0.94      1.00      0.97        16\n",
      "           4       0.75      0.50      0.60         6\n",
      "           5       0.85      0.97      0.91        35\n",
      "           6       0.97      0.89      0.93        37\n",
      "           7       0.88      0.79      0.83        28\n",
      "           8       1.00      0.85      0.92        34\n",
      "           9       1.00      0.74      0.85        42\n",
      "          10       0.89      0.97      0.93        95\n",
      "          11       1.00      0.89      0.94         9\n",
      "          12       0.83      0.71      0.77         7\n",
      "          13       0.88      0.78      0.82         9\n",
      "          14       0.80      0.67      0.73         6\n",
      "          15       0.64      0.88      0.74         8\n",
      "          16       0.25      1.00      0.40         1\n",
      "          17       0.56      1.00      0.72         9\n",
      "          18       1.00      1.00      1.00         6\n",
      "          19       1.00      0.75      0.86         8\n",
      "          20       0.86      0.86      0.86         7\n",
      "          21       0.83      1.00      0.91         5\n",
      "          22       1.00      0.88      0.93         8\n",
      "          23       1.00      1.00      1.00         4\n",
      "          24       0.00      0.00      0.00         2\n",
      "          25       0.80      0.67      0.73         6\n",
      "          26       1.00      0.92      0.96        12\n",
      "          27       0.91      0.91      0.91        11\n",
      "          28       0.50      0.67      0.57         3\n",
      "          29       1.00      1.00      1.00         4\n",
      "          30       0.33      1.00      0.50         4\n",
      "          31       0.88      1.00      0.93         7\n",
      "          32       1.00      0.86      0.92         7\n",
      "          33       0.83      1.00      0.91         5\n",
      "\n",
      "    accuracy                           0.87       548\n",
      "   macro avg       0.82      0.84      0.81       548\n",
      "weighted avg       0.89      0.87      0.87       548\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "#Dummy inputs to load model\n",
    "xs=np.zeros((8446, 32, 16, 3))\n",
    "ys=np.zeros((8446, 34))\n",
    "xt=np.zeros((109, 32, 16, 3))\n",
    "yt=np.zeros((109, 34))\n",
    "challenge_model = DANN(get_encoder(), get_task(), get_discriminator(),\n",
    "             lambda_=0.1, optimizer=Adam(0.0001),loss='CategoricalCrossentropy',metrics=[\"acc\"],random_state=0)\n",
    "challenge_model.fit(xs, ys,xt,yt, epochs=0,verbose=1,batch_size = 32) # NO fit happen, just dummy step to load model\n",
    "challenge_model.load_weights(save_check_pt+ '/challenge')\n",
    "challenge_model.score(challenge_images, challenge_labels)\n",
    "challenge_hat = challenge_model.predict(challenge_images)\n",
    "challenge_hat = np.argmax(challenge_hat,axis=1)\n",
    "challenge_labels = np.argmax(challenge_labels,axis=1)\n",
    "print(classification_report(challenge_labels, challenge_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aeef9b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 281ms/step - loss: 0.5830 - acc: 0.8866\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.78      0.85       106\n",
      "           1       0.62      0.95      0.75        37\n",
      "           2       0.85      0.98      0.91       123\n",
      "           3       0.92      0.97      0.94       121\n",
      "           4       0.73      0.90      0.80        39\n",
      "           5       0.93      0.91      0.92       122\n",
      "           6       0.90      0.93      0.91       142\n",
      "           7       0.87      0.89      0.88        75\n",
      "           8       0.95      0.90      0.92       138\n",
      "           9       0.92      0.89      0.91       139\n",
      "          10       1.00      0.91      0.95       372\n",
      "          11       0.96      0.86      0.91        28\n",
      "          12       0.72      0.97      0.83        30\n",
      "          13       1.00      0.50      0.67        14\n",
      "          14       0.84      0.73      0.78        22\n",
      "          15       0.76      0.96      0.85        23\n",
      "          16       0.82      0.88      0.85        26\n",
      "          17       0.83      0.83      0.83        23\n",
      "          18       0.73      0.90      0.81        21\n",
      "          19       0.94      0.79      0.86        19\n",
      "          20       0.85      1.00      0.92        34\n",
      "          21       1.00      0.71      0.83        17\n",
      "          22       1.00      0.82      0.90        11\n",
      "          23       0.82      0.50      0.62        18\n",
      "          24       0.71      0.71      0.71         7\n",
      "          25       0.90      0.53      0.67        17\n",
      "          26       0.41      1.00      0.58        14\n",
      "          27       0.88      0.54      0.67        13\n",
      "          28       0.95      0.91      0.93        23\n",
      "          29       0.71      0.85      0.77        20\n",
      "          30       0.67      1.00      0.80         8\n",
      "          31       1.00      0.78      0.88        23\n",
      "          32       0.78      0.88      0.82        16\n",
      "          33       0.95      0.64      0.77        28\n",
      "\n",
      "    accuracy                           0.89      1869\n",
      "   macro avg       0.85      0.83      0.82      1869\n",
      "weighted avg       0.90      0.89      0.89      1869\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "#Dummy inputs to load model\n",
    "xs=np.zeros((8446, 32, 16, 3))\n",
    "ys=np.zeros((8446, 34))\n",
    "xt=np.zeros((373, 32, 16, 3))\n",
    "yt=np.zeros((373, 34))\n",
    "db_model = DANN(get_encoder(), get_task(), get_discriminator(),\n",
    "             lambda_=0.1, optimizer=Adam(0.0001),loss='CategoricalCrossentropy',metrics=[\"acc\"],random_state=0)\n",
    "db_model.fit(xs, ys,xt,yt, epochs=0,verbose=1,batch_size = 32) # NO fit happen, just dummy step to load model\n",
    "db_model.load_weights(save_check_pt+ '/db')\n",
    "db_model.score(db_images, db_labels)\n",
    "db_hat = db_model.predict(db_images)\n",
    "db_hat = np.argmax(db_hat,axis=1)\n",
    "db_labels = np.argmax(db_labels,axis=1)\n",
    "print(classification_report(db_labels, db_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47a1c2c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 175ms/step - loss: 0.0968 - acc: 0.9753\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        16\n",
      "           1       1.00      0.90      0.95        10\n",
      "           2       1.00      1.00      1.00        14\n",
      "           3       1.00      1.00      1.00         8\n",
      "           4       0.80      0.80      0.80         5\n",
      "           5       1.00      1.00      1.00        10\n",
      "           6       1.00      1.00      1.00        13\n",
      "           7       1.00      1.00      1.00        12\n",
      "           8       1.00      0.93      0.96        14\n",
      "           9       1.00      1.00      1.00        15\n",
      "          10       0.98      1.00      0.99        52\n",
      "          11       1.00      1.00      1.00         1\n",
      "          12       1.00      1.00      1.00         6\n",
      "          13       1.00      0.75      0.86         4\n",
      "          15       1.00      1.00      1.00         2\n",
      "          16       1.00      1.00      1.00         2\n",
      "          17       1.00      1.00      1.00         4\n",
      "          18       0.86      1.00      0.92         6\n",
      "          19       1.00      1.00      1.00         1\n",
      "          20       0.90      1.00      0.95         9\n",
      "          21       1.00      1.00      1.00         3\n",
      "          22       1.00      1.00      1.00         3\n",
      "          23       0.80      1.00      0.89         4\n",
      "          25       1.00      0.88      0.93         8\n",
      "          26       1.00      1.00      1.00         1\n",
      "          27       1.00      1.00      1.00         4\n",
      "          28       1.00      1.00      1.00         4\n",
      "          30       1.00      1.00      1.00         2\n",
      "          31       1.00      1.00      1.00         6\n",
      "          32       1.00      1.00      1.00         2\n",
      "          33       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.98       243\n",
      "   macro avg       0.98      0.97      0.97       243\n",
      "weighted avg       0.98      0.98      0.98       243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "#Dummy inputs to load model\n",
    "xs=np.zeros((8446, 32, 16, 3))\n",
    "ys=np.zeros((8446, 34))\n",
    "xt=np.zeros((48, 32, 16, 3))\n",
    "yt=np.zeros((48, 34))\n",
    "fn_model = DANN(get_encoder(), get_task(), get_discriminator(),\n",
    "             lambda_=0.1, optimizer=Adam(0.0001),loss='CategoricalCrossentropy',metrics=[\"acc\"],random_state=0)\n",
    "fn_model.fit(xs, ys,xt,yt, epochs=0,verbose=1,batch_size = 32) # NO fit happen, just dummy step to load model\n",
    "fn_model.load_weights(save_check_pt+ '/fn')\n",
    "fn_model.score(fn_images, fn_labels)\n",
    "fn_hat = fn_model.predict(fn_images)\n",
    "fn_hat = np.argmax(fn_hat,axis=1)\n",
    "fn_labels = np.argmax(fn_labels,axis=1)\n",
    "print(classification_report(fn_labels, fn_hat))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
